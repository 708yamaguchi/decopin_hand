<launch>

  <arg name="use_rosbag" default="false" />
  <arg name="filename" default="" />
  <arg name="use_microphone" default="false" />
  <arg name="save_noise" default="false" />
  <arg name="save_action" default="false" />
  <arg name="save_when_action" default="false" />
  <arg name="target_class" default="no_action" />
  <arg name="classify_action" default="false" />

  <group if="$(arg use_rosbag)" >
    <param name="use_sim_time" value="true" />
    <node name="rosbag_play"
          pkg="rosbag" type="play"
          args="$(arg filename) --clock --loop"/>
  </group>

  <!-- if you want to publish /audio from microphone -->
  <group if="$(arg use_microphone)" >
    <include file="$(find audio_capture)/launch/capture.launch" >
      <arg name="device" value="hw:2,0" />
      <arg name="channels" value="1" />
      <arg name="sample_rate" value="44100" />
      <arg name="format" value="wave" />
      <arg name="ns" value="/" />
    </include>
  </group>

  <!-- convert audio topic to spectrum topic -->
  <node pkg="jsk_perception" type="audio_to_spectrum.py" name="audio_to_spectrum" respawn="true">
    <remap from="~audio" to="/audio" />
    <rosparam>
      <!-- meaning of rosparams below are described in audio_to_spectrum.py -->
      mic_sampling_rate: 44100
      fft_sampling_period: 0.1
      bitdepth: 16
      high_cut_freq: 20000
      low_cut_freq: 20
      fft_exec_rate: 50
    </rosparam>
  </node>

  <!-- convert raw spectrum topic to raw spectrogram topic -->
  <node pkg="jsk_perception" type="spectrum_to_spectrogram.py" name="spectrum_to_spectrogram" respawn="true">
    <remap from="~spectrum" to="/audio_to_spectrum/spectrum_filtered" />
    <rosparam>
      <!-- meaning of rosparams below are described in spectrum_to_spectrogram.py -->
      image_height: 300
      image_width: 300
      spectrogram_period: 0.2
    </rosparam>
  </node>

  <!-- visualize spectrum -->
  <!-- <node pkg="jsk_perception" type="spectrum_plot.py" name="spectrum_plot"  > -->
  <!--   <remap from="~spectrum" to="/audio_to_spectrum/spectrum_filtered" /> -->
  <!-- </node> -->

  <!-- Collect noise spectrum (no_action spectrum)
       which is used for both action detection and noise subtraction -->
  <node if="$(arg save_noise)" pkg="decopin_hand" type="noise_saver.py" name="noise_saver" output="screen">
    <remap from="~raw_spectrogram" to="/spectrum_to_spectrogram/spectrogram" />
    <rosparam subst_value="true">
      save_data_rate: 10 <!-- related to fft_sampling_period ? -->
    </rosparam>
  </node>

  <node unless="$(arg save_noise)" pkg="decopin_hand" type="noise_subtractor.py" name="noise_subtractor" output="screen">
    <remap from="~raw_spectrogram" to="/spectrum_to_spectrogram/spectrogram" />
  </node>

  <node unless="$(arg save_noise)" pkg="decopin_hand" type="action_detector.py" name="action_detector" output="screen">
    <remap from="~raw_spectrogram" to="/spectrum_to_spectrogram/spectrogram" />
    <rosparam subst_value="true">
      anormal_threshold: 3000
    </rosparam>
  </node>

  <!-- visualize spectrogram -->
  <!-- you can get spectrogram image topic from /spectrogram_view/output-->
  <node pkg="image_view" type="image_view" name="subtracted_spectrogram_to_jet"  >
    <remap from="image" to="/noise_subtractor/subtracted_spectrogram" />
    <rosparam>
      <!-- set all pixels between 0 and 255 -->
      do_dynamic_scaling: true
      <!-- use jet colormap -->
      colormap: 2
    </rosparam>
  </node>

  <!-- Publish whether the robot is in action or not to rostopic, by MT method. -->
  <!-- Collect spectrogram with action class, only when the robot is in action. -->
  <node if="$(arg save_action)" pkg="decopin_hand" type="action_saver.py" name="action_saver" output="screen">
    <remap from="~in_action" to="/action_detector/in_action" />
    <remap from="~subtracted_spectrogram_jet" to="/subtracted_spectrogram_to_jet/output" />
    <rosparam subst_value="true">
      <!-- params below is enabled only when save_data is true -->
      save_data_rate: 10 <!-- related to fft_sampling_period ? -->
      target_class: $(arg target_class)
      save_when_action: $(arg save_when_action)
    </rosparam>
  </node>

  <!-- Classify actions -->
  <!-- Copied from: https://github.com/start-jsk/jsk_apc/blob/master/jsk_apc2015_common/launch/vgg16_object_recognition.launch -->
  <node if="$(arg classify_action)" pkg="jsk_perception" type="vgg16_object_recognition.py" name="action_classifier" >
    <remap from="~input" to="/subtracted_spectrogram_to_jet/output" />
    <rosparam subst_value="true">
      gpu: 0
      model_name: vgg16_batch_normalization
      model_file: $(find decopin_hand)/scripts/result/model_best.npz
      target_names:
        - hit_pen
        - no_action
        - trace_human_finger
    </rosparam>
  </node>

  <!-- Visualize action classification -->
  <node if="$(arg classify_action)" name="action_classification_result"
        pkg="jsk_perception" type="draw_classification_result.py" >
    <remap from="~input" to="/action_classifier/output" />
    <remap from="~input/image" to="/subtracted_spectrogram_to_jet/output" />
  </node>

  <node if="$(arg classify_action)" pkg="image_view" type="image_view" name="classification_result_view"  >
    <remap from="image" to="/action_classification_result/output" />
  </node>


</launch>
